% UQ Gemini Poster - Custom Blue Theme (#093f81 + #d1e2f3)
% Based on: https://github.com/alfurka/gemini-uq

\documentclass[final]{beamer}

% ====================
% Packages
% ====================
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[size=custom,width=100,height=75,scale=1.0]{beamerposter}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage[table]{xcolor}  % for \rowcolors

% ====================
% Custom Blue Color Theme (replaces UChicago maroon)
% ====================
\definecolor{primaryblue}{HTML}{093f81}     % Deep blue - main accent
\definecolor{lightblue}{HTML}{d1e2f3}       % Very light blue-gray - backgrounds

\setbeamercolor{palette primary}{fg=black,bg=white}
\setbeamercolor{palette secondary}{fg=black,bg=white}
\setbeamercolor{palette tertiary}{bg=black,fg=white}
\setbeamercolor{palette quaternary}{fg=black,bg=white}
\setbeamercolor{structure}{fg=primaryblue}

% Headline (dark blue bar)
\setbeamercolor{headline}{fg=white,bg=primaryblue}
\setbeamercolor{headline rule}{bg=primaryblue!70!black}

% Blocks
\setbeamercolor{block title}{fg=primaryblue,bg=white}
\setbeamercolor{block separator}{bg=primaryblue}
\setbeamercolor{block body}{fg=black,bg=white}

% Alert blocks (light blue background)
\setbeamercolor{block alerted title}{fg=primaryblue,bg=lightblue}
\setbeamercolor{block alerted separator}{bg=primaryblue}
\setbeamercolor{block alerted body}{fg=black,bg=lightblue!80}

% Items & headings
\setbeamercolor{item}{fg=primaryblue}
\setbeamercolor{heading}{fg=primaryblue}

% Bibliography
\setbeamercolor{bibliography item}{fg=primaryblue}
\setbeamercolor{bibliography entry author}{fg=black}
\setbeamercolor{bibliography entry title}{fg=black}

% ====================
% Load Gemini Theme (after color overrides)
% ====================
\usetheme{gemini}

% ====================
% Layout
% ====================
\newlength{\sepwidth}
\newlength{\colwidth}
\setlength{\sepwidth}{0.025\paperwidth}
\setlength{\colwidth}{0.3\paperwidth}
\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

% ====================
% Your Content
% ====================
\title{The Impact of Prompt Engineering on Code Generation Accuracy and Hallucination Patterns in Language Models}

\author{Kadin Matotek \inst{1} \and Linh B. Ngo \inst{1}}
\institute[shortinst]{\inst{1} West Chester University, Department of Computer Science}

\footercontent{
  Research conducted at WCU AIR Lab \hfill
  SICCS 2025 --- Poster Session \hfill
  \href{mailto:km998744@wcupa.edu}{km998744@wcupa.edu}
}

% Optional logos (adjust paths as needed)
\logoright{\includegraphics[height=7cm]{figures/icon.png}}
\logoleft{\includegraphics[height=7cm]{figures/icon.png}}

% Custom logo overlay (uncomment if you prefer manual placement)
% \addtobeamertemplate{headline}{}
% {
%     \begin{tikzpicture}[remember picture,overlay]
%       \node[anchor=north west,inner sep=3cm] at ([xshift=0cm,yshift=1cm]current page.north west)
%         {\includegraphics[height=5cm]{figures/icon.png}};
%       \node[anchor=north east,inner sep=3cm] at ([xshift=0cm,yshift=2.5cm]current page.north east)
%         {\includegraphics[height=8cm]{figures/icon.png}};
%     \end{tikzpicture}
% }

\begin{document}

\begin{frame}[t]
\begin{columns}[t]
\separatorcolumn

% ==================== Column 1 ====================
\begin{column}{\colwidth}

\begin{block}{Introduction}
Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet their reliability remains a critical concern. This study investigates how different prompt engineering strategies affect model accuracy and hallucination patterns across coding tasks.

\textbf{Research Questions}
\begin{itemize}
  \item How do concise versus verbose instructions impact code generation accuracy?
  \item What types of errors and hallucinations emerge across different model sizes?
  \item How do reasoning strategies (Chain-of-Thought, Direct, Program-Aided) affect performance?
\end{itemize}
\end{block}

\begin{block}{Methodology}
We evaluated 5 Qwen model variants (0.5B to 14B parameters) on 323 programming problems using a systematic prompt engineering framework.

\textbf{Experimental Design}
\begin{itemize}
  \item \textbf{Base Instructions:} Concise vs. Verbose (2 options)
  \item \textbf{Reasoning Strategies:} Chain-of-Thought, Direct, Program-Aided (3 options)
  \item \textbf{Problem Decomposition:} None vs. Basic (2 options)
  \item \textbf{Output Formats:} Code only, Explanation + Code, Code + Explanation (3 options)
  \item \textbf{Prompt Variations:} $2 \times 3 \times 2 \times 3 = 36$ unique configurations
  \item \textbf{Total Solutions Generated:} $323 \text{ problems} \times 36 \text{ prompts} \times 5 \text{ models} = 58,140$ code generations
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{figures/token_efficiency.pdf}
\caption{Experimental framework showing prompt construction pipeline and evaluation methodology.}
\end{figure}
\end{block}

\begin{alertblock}{Key Finding: Conciseness Advantage}
Across all 18 prompt configuration comparisons, \textbf{concise instructions outperformed verbose ones in 94.4\%} of cases with an average improvement of +1.35\%.

This effect was most pronounced in smaller models, suggesting that verbose instructions may introduce noise that degrades performance.
\end{alertblock}

\end{column}
\separatorcolumn

% =================  Column 2 
\begin{column}{\colwidth}

\begin{block}{Results: Prompt Strategy Performance (averaged across all models)}

\textbf{Top 3 Configurations} 

\begin{table}
\centering
\small
\rowcolors{2}{lightblue!20}{white}
\begin{tabular}{l l l l r}
\toprule
\textbf{Base} & \textbf{Reasoning} & \textbf{Decomp} & \textbf{Output}       & \textbf{Acc.} \\
\midrule
Concise & Direct    & None  & Code only     & \textbf{33.10\%} \\
Concise & Direct    & None  & Exp + Code    & 32.79\% \\
Concise & CoT       & None  & Exp + Code    & 32.04\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Bottom 3 Configurations} \quad (all verbose!)

\begin{table}
\centering
\small
\rowcolors{2}{lightblue!20}{white}
\begin{tabular}{l l l l r}
\toprule
\textbf{Base} & \textbf{Reasoning} & \textbf{Decomp} & \textbf{Output}       & \textbf{Acc.} \\
\midrule
Verbose & CoT       & Basic & Code + Exp    & 28.17\% \\
Verbose & PAL       & Basic & Code + Exp    & 27.80\% \\
Verbose & PAL       & Basic & Exp + Code    & 26.78\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}
\textit{Max gap: \textbf{+6.32\%} (best concise vs worst verbose)}

\end{block}

\begin{block}{Model Size Effects}
\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{figures/reasoning_strategy.pdf}
\caption{Accuracy comparison showing concise prompts consistently outperform verbose across all model sizes. The advantage diminishes as models grow larger.}
\end{figure}


\end{block}

\end{column}
\separatorcolumn

% ==================== Column 3 ====================
\begin{column}{\colwidth}

\begin{block}{Error and Hallucination Analysis}
We manually defined and annotated 28 distinct error types. Crucially, we observe:

\vspace{0.5em}
\textbf{Highly reproducible hallucination profiles:} Independent runs (v1 vs v2) produce nearly identical error distributions (overlapping solid/dashed lines).

\textbf{Systematic shift with model scale:} Larger models dramatically reduce the dominant error mode while maintaining the same overall failure pattern.

\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{figures/hallucination_stability.pdf}
\caption{\textbf{Hallucination profiles are remarkably stable across independent runs} (solid vs dashed lines nearly overlap) but \textbf{shift predictably with model size}.}
\end{figure}

\textbf{Most Common Error Types}
\begin{itemize}
  \item \textbf{Logic Deviation} (41.6\%): Incorrect algorithmic approach
  \item \textbf{ValueError} (12.9\%): Invalid input handling
  \item \textbf{TypeError} (2.9\%): Type mismatches
  \item \textbf{IndexError} (3.1\%): Array boundary violations
  \item \textbf{NameError} (2.8\%): Undefined variables
\end{itemize}

\end{block}

\begin{block}{Conclusions}

\textbf{Key Takeaways}
\begin{itemize}
  \item Concise prompts consistently outperform verbose alternatives
  \item Smaller models are more sensitive to prompt engineering
  \item Logic deviations are the dominant failure mode
  \item Reasoning strategy and output format significantly affect accuracy
\end{itemize}

\end{block}

\begin{block}{References}
\nocite{*}
\small\bibliographystyle{plain}\bibliography{poster}
\end{block}

\end{column}
\separatorcolumn

\end{columns}
\end{frame}

\end{document}